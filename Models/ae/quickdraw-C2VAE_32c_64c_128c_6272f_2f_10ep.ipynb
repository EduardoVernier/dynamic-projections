{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Shared' from '../Shared.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "sys.path.append('..')\n",
    "import Shared # Shared.py holds functions common to all notebooks\n",
    "importlib.reload(Shared) # In case you make changes to the Shared.py file and don't want to restart the nb kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_name = 'quickdraw-C2VAE_32c_64c_128c_6272f_2f_10ep'  # Couldn't figure out how to get this automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53400,\n",
       " 53400,\n",
       " 89,\n",
       " {0: 'airplane',\n",
       "  1: 'banana',\n",
       "  2: 'baseball',\n",
       "  3: 'bicycle',\n",
       "  4: 'carrot',\n",
       "  5: 'cello'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, info_df, n_revisions, CATEGORIES = Shared.load_drawings('../../Datasets/quickdraw/')\n",
    "# Flatten Nx28x28 -> Nx784x1\n",
    "N = len(X)\n",
    "# np.reshape(X, (len(X), 1, 784))\n",
    "# X_flat = np.reshape(np.ravel(X), (N, -1))\n",
    "len(X), len(info_df), n_revisions, CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_index</th>\n",
       "      <th>drawing_cat_id</th>\n",
       "      <th>drawing_cat_str</th>\n",
       "      <th>drawing_id</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>cello</td>\n",
       "      <td>113947</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>carrot</td>\n",
       "      <td>41438</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>29295</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>carrot</td>\n",
       "      <td>94260</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>18402</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_index  drawing_cat_id drawing_cat_str  drawing_id   t\n",
       "0        0               5           cello      113947  41\n",
       "1        1               4          carrot       41438  42\n",
       "2        2               3         bicycle       29295  36\n",
       "3        3               4          carrot       94260  79\n",
       "4        4               3         bicycle       18402  58"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eduardo/.local/share/virtualenvs/dynamic-projections-ak_z834q/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_lvar = args\n",
    "    \n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    \n",
    "    # By default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    \n",
    "    return z_mean + K.exp(0.5*z_lvar)*epsilon\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(28, 28, 1), name='encoder_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(2, name='z_mean')(x)\n",
    "z_lvar = Dense(2, name='z_lvar')(x)\n",
    "l_code = Lambda(sampling, name='l_code')([z_mean, z_lvar])\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_lvar, l_code], name='encoder')\n",
    "\n",
    "# Decoder\n",
    "encoded = Input(shape=(2,), name='z_sampled')\n",
    "x = Dense(6272)(encoded)\n",
    "x = Reshape((7, 7, 128))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "output = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "decoder = Model(encoded, output, name='decoder')\n",
    "\n",
    "# VAE\n",
    "va_out = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, va_out, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 128)    73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6272)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            12546       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_lvar (Dense)                  (None, 2)            12546       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "l_code (Lambda)                 (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_lvar[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 117,764\n",
      "Trainable params: 117,764\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampled (InputLayer)       (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6272)              18816     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 258,945\n",
      "Trainable params: 258,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 117764    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 28, 28, 1)         258945    \n",
      "=================================================================\n",
      "Total params: 376,709\n",
      "Trainable params: 376,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()\n",
    "decoder.summary()\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_img = Input(shape=(28, 28, 1))\n",
    "# # input_img = Input(shape=(28, 28, 1))\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "# x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# # encoded = Conv2D(2, (2, 2), activation='relu', padding='same', strides=(1,4))(x)\n",
    "# x = Flatten()(x)\n",
    "# encoded = Dense(2)(x)\n",
    "# x = Dense(1568)(encoded)\n",
    "# x = Reshape((7,7,32))(x)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = UpSampling2D((2,2))(x)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = UpSampling2D((2,2))(x)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# decoded = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# ae = Model(input_img, decoded)\n",
    "# encoder = Model(input_img, encoded)\n",
    "# ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build VAE loss function. It takes into account the variance layer outputs too.\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(va_out))\n",
    "reconstruction_loss *= 784\n",
    "kl_loss = 1 + z_lvar - K.square(z_mean) - K.exp(z_lvar)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and summary\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_test) = train_test_split(np.array(X).reshape([-1, 28, 28, 1]), test_size=0.1, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48060, 28, 28, 1), (5340, 28, 28, 1), (None, 28, 28, 1), (None, 28, 28, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, vae.input_shape, vae.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eduardo/.local/share/virtualenvs/dynamic-projections-ak_z834q/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48060 samples, validate on 5340 samples\n",
      "Epoch 1/10\n",
      "48060/48060 [==============================] - 419s 9ms/step - loss: 65.1187 - val_loss: 64.0502\n",
      "Epoch 2/10\n",
      "48060/48060 [==============================] - 413s 9ms/step - loss: 63.3731 - val_loss: 63.1539\n",
      "Epoch 3/10\n",
      "48060/48060 [==============================] - 408s 8ms/step - loss: 62.5550 - val_loss: 62.2324\n",
      "Epoch 4/10\n",
      "48060/48060 [==============================] - 401s 8ms/step - loss: 61.7051 - val_loss: 61.7941\n",
      "Epoch 5/10\n",
      "48060/48060 [==============================] - 402s 8ms/step - loss: 60.9979 - val_loss: 60.8449\n",
      "Epoch 6/10\n",
      "48060/48060 [==============================] - 402s 8ms/step - loss: 60.2425 - val_loss: 60.3609\n",
      "Epoch 7/10\n",
      "48060/48060 [==============================] - 403s 8ms/step - loss: 59.6482 - val_loss: 59.8194\n",
      "Epoch 8/10\n",
      "48060/48060 [==============================] - 410s 9ms/step - loss: 58.9708 - val_loss: 58.9642\n",
      "Epoch 9/10\n",
      "48060/48060 [==============================] - 417s 9ms/step - loss: 58.4354 - val_loss: 58.6359\n",
      "Epoch 10/10\n",
      "48060/48060 [==============================] - 419s 9ms/step - loss: 57.9226 - val_loss: 58.0728\n"
     ]
    }
   ],
   "source": [
    "# Train the VAE.\n",
    "h = vae.fit(x_train, epochs=10, batch_size=32, validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6bc0e6898>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0:1].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6bc0648d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(vae.predict(x_test[0:1]).reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save('../Models/{}.h5'.format(nb_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# ae = load_model('../Models/{}.h5'.format(nb_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(ae.history.history['loss'])\n",
    "# plt.suptitle('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shared.save_quickdraw_activations(ae, np.array(X).reshape([-1, 28, 28, 1]), info_df, n_revisions, nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all activations\n",
    "layer_output = encoder.predict(np.array(X).reshape([-1, 28, 28, 1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53400, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write activations to csv\n",
    "header = ['id']\n",
    "for t in range(n_revisions):\n",
    "    for d in range(layer_output.shape[1]):\n",
    "        header.append('t{}d{}'.format(t, d))\n",
    "\n",
    "csv_out = []\n",
    "gb = info_df.groupby(['drawing_cat_str', 'drawing_id'])\n",
    "for index, df in gb:  # Iterave over all drawing sequences\n",
    "    drawing_id = index[0] + '-' + str(index[1])\n",
    "    item_row = [drawing_id]\n",
    "    for index, _ in df.sort_values('t').iterrows():  # For all timesteps\n",
    "        for d in range(layer_output.shape[1]):  # Add all dimensions\n",
    "            item_row.append(layer_output[index][d])\n",
    "    csv_out.append(item_row)\n",
    "\n",
    "df_out = pd.DataFrame(csv_out, columns=header)\n",
    "df_out.to_csv('../../Output/{}.csv'.format(nb_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
