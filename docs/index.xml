<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Introduction on Dynamic projections</title><link>https://eduardovernier.github.io/dynamic-projections/</link><description>Recent content in Introduction on Dynamic projections</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://eduardovernier.github.io/dynamic-projections/index.xml" rel="self" type="application/rss+xml"/><item><title>Raw output</title><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/results/raw-output/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/results/raw-output/</guid><description>Raw output Note that s1 is equivalent to the timeframe (TF) version described in the paper and s4 is equivalent to the global (G) version.
cartolastd cifar10cnn esc50 gaussians cartolastd-AE_10f_10f_2f_50ep.csv cifar10cnn-AE_10f_10f_2f_20ep.csv esc50-AE_10f_10f_2f_40ep.csv gaussians-AE_10f_10f_2f_20ep.csv cartolastd-VAE_10f_10f_2f_100ep.csv cifar10cnn-VAE_100f_10f_2f_20ep.csv esc50-VAE_100f_10f_2f_20ep.csv gaussians-VAE_100f_10f_2f_20ep.csv cartolastd-tsne_s1_30p.csv cifar10cnn-tsne_s1_30p.csv esc50-tsne_s1_30p.csv gaussians-tsne_s1_30p.csv cartolastd-tsne_s4_30p.csv cifar10cnn-tsne_s4_30p.csv esc50-tsne_s4_30p.csv gaussians-tsne_s4_30p.csv cartolastd-dtsne_100p_0-1l.csv cifar10cnn-dtsne_30p_0-1l.csv esc50-dtsne_40p_0-05l.csv gaussians-dtsne_70p_0-1l.csv cartolastd-umap_s1_15p.csv cifar10cnn-umap_s1_15p.csv esc50-umap_s1_15p.csv gaussians-umap_s1_15p.</description></item><item><title>Videos and Trails</title><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/results/videos-and-trails/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/results/videos-and-trails/</guid><description>Videos and Trails 1. cartolastd - 696 observations - 19 timesteps - 17 dimensions - 5 classes ... The dataset was scrapped from the Brazilian fantasy soccer platform Cartola and represents the second turn of the 2017 championship. The scrapper source can be found at https://github.com/henriquepgomide/caRtola. To make the dataset smoother, the dimensions were cumulatively averaged.
2. cifar10cnn - 1000 observations - 30 timesteps - 10 dimensions - 10 classes .</description></item><item><title>Replication</title><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/replication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/replication/</guid><description>Replication FIrst clone this repo: https://github.com/EduardoVernier/dynamic-projections
Recreating the results / Testing new methods and datasets Set up virtual env and dependencies using pipenv. https://pipenv.readthedocs.io/en/latest/
pip install pipenv pipenv run pip install pip==18.0 pipenv install sudo apt-get install python3-tk To run a script use pipenv run python &amp;lt;script_name&amp;gt;.py. To open notebooks use pipenv run jupyter notebook or create a new shell with pipenv shell and then call jupyter notebook.</description></item><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/algorithms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/algorithms/</guid><description>Algorithms PCA - A technique for dimensionality reduction that performs a linear mapping of the data to a lower-dimensional space maximizing the variance of the data in the low-dimensional representation. We created a wrapper that around the scikit-learn implementation that offers two usage modes: Strategy TF (pca_s1) computes PCA independently for each timestep. Strategy G (pca_s4) works by grouping all timesteps and computing PCA once. The terminology was borrowed from the dt-SNE paper.</description></item><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/datasets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/datasets/</guid><description>Datasets dataset_id and download url n_items n_timesteps n_dims n_classes avg_intrinsic_dim avg_sparsity_ratio 1 cartolastd 696 19 17 5 0.6470 0.0 2 cifar10cnn 1000 30 10 10 0.6599 0.0 3 esc50 320 108 128 8 0.0345 0.0 4 fashion 1000 10 784 10 0.4762 0.2971 5 gaussians 2000 10 100 10 0.3680 0.0 6 nnset 80 30 8070 8 0.</description></item><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/metrics/</guid><description>Quality metrics https://github.com/EduardoVernier/dynamic-projections/blob/master/Metrics/template.ipynb
The code for the metrics is located in a notebook called template.ipynb. For each dataset we use a tool called Papermill to instantiate a new notebook from the template. The two parameters that are needed are the output notebook path (remember to change name to dataset_id) and the list of output/projection files we want to analyse. This is the code that generates the analysis for the gaussians dataset:</description></item></channel></rss>