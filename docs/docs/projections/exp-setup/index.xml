<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Experimental setup on Dynamic projections</title><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/</link><description>Recent content in Experimental setup on Dynamic projections</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/algorithms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/algorithms/</guid><description>Algorithms PCA - A technique for dimensionality reduction that performs a linear mapping of the data to a lower-dimensional space maximizing the variance of the data in the low-dimensional representation. We created a wrapper that around the scikit-learn implementation that offers two usage modes: Strategy TF (pca_s1) computes PCA independently for each timestep. Strategy G (pca_s4) works by grouping all timesteps and computing PCA once. The terminology was borrowed from the dt-SNE paper.</description></item><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/datasets/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/datasets/</guid><description>Datasets dataset_id and download url n_items n_timesteps n_dims n_classes avg_intrinsic_dim avg_sparsity_ratio 1 cartolastd 696 19 17 5 0.6470 0.0 2 cifar10cnn 1000 30 10 10 0.6599 0.0 3 esc50 320 108 128 8 0.0345 0.0 4 fashion 1000 10 784 10 0.4762 0.2971 5 gaussians 2000 10 100 10 0.3680 0.0 6 nnset 80 30 8070 8 0.</description></item><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/metrics/</guid><description>Quality metrics https://github.com/EduardoVernier/dynamic-projections/blob/master/Metrics/template.ipynb
The code for the metrics is located in a notebook called template.ipynb. For each dataset we use a tool called Papermill to instantiate a new notebook from the template. The two parameters that are needed are the output notebook path (remember to change name to dataset_id) and the list of output/projection files we want to analyse. This is the code that generates the analysis for the gaussians dataset:</description></item><item><title/><link>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/plots/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://eduardovernier.github.io/dynamic-projections/docs/projections/exp-setup/plots/</guid><description>Plots Figure 1 Figure 2 Figure 3 Figure 4 Aggregated metric results over all datasets. Twelve spatial quality and temporal stability metrics evaluated for 9 DR methods run on ten datasets. Note that here we&#39;ve added the results of convolutional methods to the analysis.</description></item></channel></rss>