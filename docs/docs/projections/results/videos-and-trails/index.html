<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Videos and Trails"><meta property="og:description" content="Videos and Trails  1. cartolastd - 696 observations - 19 timesteps - 17 dimensions - 5 classes ...  The dataset was scrapped from the Brazilian fantasy soccer platform Cartola and represents the second turn of the 2017 championship. The scrapper source can be found at https://github.com/henriquepgomide/caRtola. To make the dataset smoother, the dimensions were cumulatively averaged.
      2. cifar10cnn - 1000 observations - 30 timesteps - 10 dimensions - 10 classes ."><meta property="og:type" content="article"><meta property="og:url" content="https://eduardovernier.github.io/dynamic-projections/docs/projections/results/videos-and-trails/"><title>Videos and Trails | Dynamic projections</title><link rel=icon href=/dynamic-projections/favicon.png type=image/x-icon><link rel=stylesheet href=/dynamic-projections/book.min.e095d2fc282039b2e0a50cefad944330a73f934c3bd2b9272bb3fdfeb8f4f34d.css integrity="sha256-4JXS/CggObLgpQzvrZRDMKc/k0w70rknK7P9/rj0800="></head><body><input type=checkbox class=hidden id=menu-control><main class="flex container"><aside class="book-menu fixed"><nav><h2 class=book-brand><a href=https://eduardovernier.github.io/dynamic-projections/><span>Dynamic projections</span></a></h2><ul><li class=book-section-flat><a href=/dynamic-projections/docs/projections/exp-setup/>Experimental setup</a><ul><li><a href=/dynamic-projections/docs/projections/exp-setup/algorithms/>Algorithms</a></li><li><a href=/dynamic-projections/docs/projections/exp-setup/datasets/>Datasets</a></li><li><a href=/dynamic-projections/docs/projections/exp-setup/metrics/>Metrics</a></li></ul></li><li class=book-section-flat><a href=/dynamic-projections/docs/projections/results/>Results</a><ul><li><a href=/dynamic-projections/docs/projections/results/raw-output/>Raw output</a></li><li><a href=/dynamic-projections/docs/projections/results/videos-and-trails/ class=active>Videos and Trails</a></li></ul></li><li><a href=/dynamic-projections/docs/projections/replication/>Replication</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class="flex align-center justify-between book-header"><label for=menu-control><img src=/dynamic-projections/svg/menu.svg alt=Menu></label>
<strong>Videos and Trails</strong></header><article class=markdown><h1 id=videos-and-trails>Videos and Trails</h1><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>1. cartolastd - 696 observations - 19 timesteps - 17 dimensions - 5 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>The dataset was scrapped from the Brazilian fantasy soccer platform Cartola and represents the second turn of the 2017 championship. The scrapper source can be found at <a href=https://github.com/henriquepgomide/caRtola>https://github.com/henriquepgomide/caRtola</a>. To make the dataset smoother, the dimensions were cumulatively averaged.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/SKcRJRXL5cg style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-cartolastd.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>2. cifar10cnn - 1000 observations - 30 timesteps - 10 dimensions - 10 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>I took the example CNN available at the keras website (<a href=https://keras.io/examples/cifar10_cnn/>https://keras.io/examples/cifar10_cnn/</a>) and looked at the output of the last layer after each epoch for 1000 images of the validation set. After 30 epochs the CNN had an accuracy of 0.6950.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/jaoB6aJVG4s style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-cifar10cnn.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>3. esc50 - 320 observations - 108 timesteps - 128 dimensions - 8 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>Sound samples of 8 classes (brushing_teeth, chainsaw, crying_baby, engine, laughing, rain, siren, wind) compressed to 128 frequencies and smoothed over time. Collected from <a href=https://github.com/karoldvl/ESC-50>https://github.com/karoldvl/ESC-50</a> by K. J. Piczak.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/FZEpRadyAN0 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-esc50.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>4. fashion - 1000 observations - 10 timesteps - 784 dimensions (28x28 pixels) - 10 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>100 images from each class (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot) were selected and added decreasing amounts of noise.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/IXicmZ5h8yI style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-fashion.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>5. gaussians - 2000 observations - 10 timesteps - 100 dimensions - 10 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>Dataset from Rauber et. al&rsquo;s dt-sne paper. “We create the multivariate Gaussians dataset specifically as a controlled experiment for dynamic t-SNE. Firstly, we sample 200 observations from each of 10 distinct (isotropic) 100-dimensional multivariate Gaussian distributions with variance 0.1. We combine the resulting 2000 observations into a single dataset D[1]. Each multivariate Gaussian has a distinct mean, which is chosen uniformly between the standard basis vectors for R 100 . Given D[t], the dataset D[t + 1] is created as follows. Each observation x[t + 1] ∈ D[t + 1] corresponds to an observation x[t] ∈ D[t] moved 10% of the remaining distance closer to the mean of its corresponding multivariate Gaussian. In simple terms, each of the 10 clusters becomes more compact as t increases. We consider T = 10 datasets.”</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/8RcAyrBywdw style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-gaussians.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>6. nnset - 80 observations - 30 timesteps - 8070 dimensions - 8 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>This dataset represents the internal states (weights and biases) of a set of neural networks learning to classify MNIST with same architecture but using different optimizers, batch sizes, training data sizes. There doesn&rsquo;t seem to be a clear class separation in this dataset.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/rcdcES9Ei8k style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-nnset.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>7. qtables - 180 observations - 40 timesteps - 1200 dimensions - 9 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>Each observation is an agent learning to move a car up a hill using the reinforcement learning algorithm Q-learning. The classes represent variations of learning rates and discounts. The car has 3 actions, and the decision space has 2 features, each divided into 20 discrete steps. Therefore the dataset is 3x20x20 or 1200 dimensions. Code based on this tutorial: <a href=https://pythonprogramming.net/q-learning-reinforcement-learning-python-tutorial/>https://pythonprogramming.net/q-learning-reinforcement-learning-python-tutorial/</a>.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/soTidu-0xd4 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-qtables.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>8. quickdraw - 600 observations - 89 timesteps - 784 dimensions (28x28 pixels) - 6 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>Google has a little fun project called Quick Draw (<a href=https://quickdraw.withgoogle.com/data>https://quickdraw.withgoogle.com/data</a>). It’s a website where they give you a few seconds to draw some object while a neural network is trying to guess what is it that you are trying to draw. What I did was extract drawing sequences for 600 objects of 6 different classes drawn by random people. In my sample, each final drawing is composed of an average of 36.1 partial drawings. Each image is a 28x28 pixel binary map.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/MIj8yY6iPtI style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-quickdraw.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>9. sorts - 80 observations - 100 timesteps - 100 dimensions - 8 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>Intermediate states of 8 sorting algorithms. Arrays initially have 100 random elements. Based on franciscouzo.github.io/sort/</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/X86myugVDVY style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-sorts.png?raw=true" alt></p></div></label></div><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>10. walk - 300 observations - 50 timesteps - 100 dimensions - 3 classes</span>
<span>...</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><p>There are three classes, in one the values of the dimensions start low and go high, one the values start high and decrease over time, and in the last, they stay roughly the same. For all of them, there is noise added (see example). This is supposed to be a &ldquo;ground-truth&rdquo; dataset with simple dynamics.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/VJWRNnnKyp4 style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><p><img src="https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs/trails-walk.png?raw=true" alt></p></div></label></div><p>Youtube playlist: <a href="https://www.youtube.com/playlist?list=PLy5Y4CMtJ7mIWjq8Sx1-mij5LxSv589wo">https://www.youtube.com/playlist?list=PLy5Y4CMtJ7mIWjq8Sx1-mij5LxSv589wo</a></p><p>Trails: <a href=https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs>https://github.com/EduardoVernier/dynamic-projections/blob/master/Plots/Figs</a></p></article></div><aside class="book-toc levels-6 fixed"><nav id=TableOfContents><ul><li><a href=#videos-and-trails>Videos and Trails</a></li></ul></nav></aside></main></body></html>