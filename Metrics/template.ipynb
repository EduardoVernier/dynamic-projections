{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is the parameters cell\n",
    "# projection_paths = './Output/quickdraw-pca_s4.csv'\n",
    "projection_paths = './Output/gaussians-pca_s4.csv ./Output/gaussians-AE_10f_2f_20ep.csv ./Output/gaussians-dtsne_70p_0-1l.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Output/gaussians-pca_s4.csv', './Output/gaussians-AE_10f_2f_20ep.csv', './Output/gaussians-dtsne_70p_0-1l.csv'] gaussians\n"
     ]
    }
   ],
   "source": [
    "projection_paths = projection_paths.split(' ')\n",
    "dataset_id = projection_paths[0].split('/')[-1].split('-')[0]\n",
    "print(projection_paths, dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import math\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "IMAGE_DATASETS = ['quickdraw', 'fashion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:00<00:00, 1231.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(600, 88)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_md_dists(dataset_path):\n",
    "    df = pd.read_csv(dataset_path, index_col=0)\n",
    "    dists = []\n",
    "    for poly in tqdm(df.values.reshape(len(df), -1, 2)):\n",
    "        dists_i = []\n",
    "        for i in range(len(poly)-1):\n",
    "            dists_i.append(math.sqrt(np.sum(np.square(poly[i] - poly[i+1]))))\n",
    "        dists.append(np.array(dists_i))\n",
    "    return np.array(dists), df.index, len(poly)\n",
    "\n",
    "get_md_dists('./Output/quickdraw-pca_s4.csv')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_dataset_to_array(dataset_path):\n",
    "    # Convert image to np array\n",
    "    # Preload images to memory (trying to speed things up)\n",
    "    all_files = glob.glob('{}*'.format(dataset_path))\n",
    "    # Gather ids and timestep info    \n",
    "    max_t = {}\n",
    "    for f in all_files:\n",
    "        regex = r\".*/{}/(.*-.*)-(.*).png\".format(dataset_id)\n",
    "        match = re.match(regex, f)\n",
    "        img_id, t = match.groups()\n",
    "        t = int(t)\n",
    "        max_t[img_id] = max_t[img_id] if img_id in max_t and max_t[img_id] > t else t   \n",
    "    \n",
    "    img_size = 28 * 28  # Pixel count\n",
    "    n_revisions = max(max_t.values()) + 1\n",
    "    n_items = len(max_t.values())\n",
    "    vs = np.empty((n_revisions, n_items, img_size))\n",
    "    \n",
    "    # Populate vs\n",
    "    for i, img_id in enumerate(natsorted(max_t)):\n",
    "        # Copy existing bitmaps to np.array\n",
    "        for t in range(0, max_t[img_id]):\n",
    "            img_file = dataset_path + img_id + '-' + str(t) + '.png'\n",
    "            vs[t][i] = (cv2.imread(img_file, cv2.IMREAD_GRAYSCALE) / 255.).flatten()\n",
    "        # Replicate last image\n",
    "        for t in range(max_t[img_id], n_revisions):\n",
    "            img_file = dataset_path + img_id + '-' + str(max_t[img_id]-1) + '.png'\n",
    "            vs[t][i] = (cv2.imread(img_file, cv2.IMREAD_GRAYSCALE) / 255.).flatten()\n",
    "    \n",
    "    return vs, list(natsorted(max_t)), n_revisions\n",
    "\n",
    "\n",
    "def tabular_dataset_to_array(dataset_path):\n",
    "    # Get files with coords and save in an array vs\n",
    "    all_files = natsorted(glob.glob('{}*'.format(dataset_path)))\n",
    "    vs = [pd.read_csv(f, index_col=0).values for f in all_files] \n",
    "    # Get dataset info \n",
    "    df_temp = pd.read_csv(all_files[0], index_col=0)\n",
    "    n_timesteps = len(all_files)\n",
    "    return np.array(vs), list(df_temp.index), n_timesteps\n",
    "\n",
    "\n",
    "def get_nd_dists(dataset_id):\n",
    "    dists = []\n",
    "    dataset_path = './Datasets/' + dataset_id + '/'\n",
    "    # Get the nd data into arrays\n",
    "    if dataset_id in IMAGE_DATASETS:\n",
    "        vs, indexes, n_timesteps = image_dataset_to_array(dataset_path)\n",
    "    else:\n",
    "        vs, indexes, n_timesteps = tabular_dataset_to_array(dataset_path)\n",
    "    # Compute dists between 2 nd arrays\n",
    "    for t in tqdm(range(n_timesteps - 1)):\n",
    "        v_t = vs[t]\n",
    "        v_tp1 = vs[t+1]\n",
    "        dists_t = []\n",
    "        for a, b in zip(v_t, v_tp1):\n",
    "            dists_t.append(math.sqrt(np.sum(np.square(a - b))))\n",
    "        dists.append(np.array(dists_t)) \n",
    "    return np.array(dists).T, indexes, n_timesteps\n",
    "\n",
    "# dists, indexes, n_timesteps = get_nd_dists('quickdraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 63.15it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 10440.51it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 10012.41it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 10585.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute distances\n",
    "dists_nd, indexes, n_timesteps = get_nd_dists(dataset_id)\n",
    "dists_md_dict = {}\n",
    "for p in projection_paths:\n",
    "    dists, _, _ = get_md_dists(p)\n",
    "    dists_md_dict[p] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9)\n",
      "(2000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(dists_nd.shape)\n",
    "print(dists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_ids = ['stab_pearson', 'stab_spearman', 'stab_kendall', 'stab_kl', 'stab_stress_n', 'stab_stress_s',\n",
    "              'spat_knn_5', 'spat_knn_10', 'spat_knn_15', 'spat_knn_20']\n",
    "metric_results = pd.DataFrame(np.zeros((len(projection_paths), len(metric_ids))),\n",
    "                              index=projection_paths, columns=metric_ids)\n",
    "metric_results = metric_results.reindex(sorted(metric_results.columns), axis=1)\n",
    "# metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spat_knn_10</th>\n",
       "      <th>spat_knn_15</th>\n",
       "      <th>spat_knn_20</th>\n",
       "      <th>spat_knn_5</th>\n",
       "      <th>stab_kendall</th>\n",
       "      <th>stab_kl</th>\n",
       "      <th>stab_pearson</th>\n",
       "      <th>stab_spearman</th>\n",
       "      <th>stab_stress_n</th>\n",
       "      <th>stab_stress_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./Output/gaussians-pca_s4.csv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.790809</td>\n",
       "      <td>0.165721</td>\n",
       "      <td>0.841275</td>\n",
       "      <td>0.945271</td>\n",
       "      <td>0.398367</td>\n",
       "      <td>0.317449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Output/gaussians-AE_10f_2f_20ep.csv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716211</td>\n",
       "      <td>0.347662</td>\n",
       "      <td>0.724679</td>\n",
       "      <td>0.898326</td>\n",
       "      <td>0.631422</td>\n",
       "      <td>0.550641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Output/gaussians-dtsne_70p_0-1l.csv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694352</td>\n",
       "      <td>0.237730</td>\n",
       "      <td>0.811766</td>\n",
       "      <td>0.868227</td>\n",
       "      <td>0.478215</td>\n",
       "      <td>0.376469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       spat_knn_10  spat_knn_15  spat_knn_20  \\\n",
       "./Output/gaussians-pca_s4.csv                  0.0          0.0          0.0   \n",
       "./Output/gaussians-AE_10f_2f_20ep.csv          0.0          0.0          0.0   \n",
       "./Output/gaussians-dtsne_70p_0-1l.csv          0.0          0.0          0.0   \n",
       "\n",
       "                                       spat_knn_5  stab_kendall   stab_kl  \\\n",
       "./Output/gaussians-pca_s4.csv                 0.0      0.790809  0.165721   \n",
       "./Output/gaussians-AE_10f_2f_20ep.csv         0.0      0.716211  0.347662   \n",
       "./Output/gaussians-dtsne_70p_0-1l.csv         0.0      0.694352  0.237730   \n",
       "\n",
       "                                       stab_pearson  stab_spearman  \\\n",
       "./Output/gaussians-pca_s4.csv              0.841275       0.945271   \n",
       "./Output/gaussians-AE_10f_2f_20ep.csv      0.724679       0.898326   \n",
       "./Output/gaussians-dtsne_70p_0-1l.csv      0.811766       0.868227   \n",
       "\n",
       "                                       stab_stress_n  stab_stress_s  \n",
       "./Output/gaussians-pca_s4.csv               0.398367       0.317449  \n",
       "./Output/gaussians-AE_10f_2f_20ep.csv       0.631422       0.550641  \n",
       "./Output/gaussians-dtsne_70p_0-1l.csv       0.478215       0.376469  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80 ms, sys: 0 ns, total: 80 ms\n",
      "Wall time: 81.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Flatten the data\n",
    "dists_nd = dists_nd.flatten()\n",
    "for p in projection_paths:\n",
    "    dists_md = dists_md_dict[p].flatten()\n",
    "\n",
    "    # Correlation and divergence metrics\n",
    "    metric_results.loc[p]['stab_pearson']  = scipy.stats.pearsonr(dists_nd, dists_md)[0]\n",
    "    metric_results.loc[p]['stab_spearman'] = scipy.stats.spearmanr(dists_nd, dists_md)[0]\n",
    "    metric_results.loc[p]['stab_kendall']  = scipy.stats.kendalltau(dists_nd, dists_md)[0]\n",
    "    metric_results.loc[p]['stab_kl']       = scipy.stats.entropy(dists_nd, dists_md)\n",
    "\n",
    "    # Stress metrics\n",
    "    nd = dists_nd / max(dists_nd)\n",
    "    md = dists_md / max(dists_md)\n",
    "    metric_results.loc[p]['stab_stress_n'] = np.sum(np.square(nd - md)) / np.sum(np.square(nd))\n",
    "\n",
    "    nd = (dists_nd - np.mean(dists_nd)) / np.std(dists_nd)\n",
    "    md = (dists_md - np.mean(dists_md)) / np.std(dists_md)\n",
    "    metric_results.loc[p]['stab_stress_s'] = np.sum(np.square(nd - md)) / np.sum(np.square(nd))\n",
    "\n",
    "display(metric_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [2, 1],\n",
       "       [3, 4],\n",
       "       [4, 3],\n",
       "       [5, 4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "_, indices = nbrs.kneighbors(X)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
