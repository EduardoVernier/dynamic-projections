{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is the parameters cell\n",
    "# projection_paths = './Output/sorts-tsne_s1_30p.csv'\n",
    "\n",
    "projection_paths = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Output/sorts-tsne_s1_30p.csv'] sorts\n"
     ]
    }
   ],
   "source": [
    "projection_paths = projection_paths.split(' ')\n",
    "dataset_id = projection_paths[0].split('/')[-1].split('-')[0]\n",
    "print(projection_paths, dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import math\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "import sys\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# # Uncomment next line if testing\n",
    "# os.chdir('..')\n",
    "\n",
    "IMAGE_DATASETS = ['quickdraw', 'fashion']\n",
    "# K_VALUES = [.05, .1, .15, .2] \n",
    "K_VALUES = [i/100 for i in range(1,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = 'Metrics/log_' + dataset_id\n",
    "!touch log \n",
    "sys.stderr = open('Metrics/log_' + dataset_id, 'w') # to check tqdm progress followed by watch -n 1 cat logfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_projection_as_array(dataset_path):\n",
    "    df = pd.read_csv(dataset_path, index_col=0)\n",
    "    vs = df.values.reshape(len(df), -1, 2)\n",
    "    return vs, list(df.index), vs.shape[1]\n",
    "\n",
    "\n",
    "def get_md_mov(dataset_path):\n",
    "    vs, indexes, n_timesteps = get_projection_as_array(dataset_path)\n",
    "    mov = []\n",
    "    for poly in vs:\n",
    "        mov_i = []\n",
    "        for i in range(len(poly)-1):\n",
    "            mov_i.append(math.sqrt(np.sum(np.square(poly[i] - poly[i+1]))))\n",
    "        mov.append(np.array(mov_i))\n",
    "    return np.array(mov), indexes, n_timesteps\n",
    "\n",
    "\n",
    "# get_md_mov('./Output/quickdraw-pca_s4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_dataset_to_array(dataset_path):\n",
    "    # Convert image to np array\n",
    "    # Preload images to memory (trying to speed things up)\n",
    "    all_files = glob.glob('{}*'.format(dataset_path))\n",
    "    # Gather ids and timestep info    \n",
    "    max_t = {}\n",
    "    for f in all_files:\n",
    "        regex = r\".*/{}/(.*-.*)-(.*).png\".format(dataset_id)\n",
    "        match = re.match(regex, f)\n",
    "        img_id, t = match.groups()\n",
    "        t = int(t)\n",
    "        max_t[img_id] = max_t[img_id] if img_id in max_t and max_t[img_id] > t else t   \n",
    "    \n",
    "    img_size = 28 * 28  # Pixel count\n",
    "    n_revisions = max(max_t.values()) + 1\n",
    "    n_items = len(max_t.values())\n",
    "    vs = np.empty((n_revisions, n_items, img_size))\n",
    "    \n",
    "    # Populate vs\n",
    "    for i, img_id in enumerate(natsorted(max_t)):\n",
    "        # Copy existing bitmaps to np.array\n",
    "        for t in range(0, max_t[img_id]):\n",
    "            img_file = dataset_path + img_id + '-' + str(t) + '.png'\n",
    "            vs[t][i] = (cv2.imread(img_file, cv2.IMREAD_GRAYSCALE) / 255.).flatten()\n",
    "        # Replicate last image\n",
    "        for t in range(max_t[img_id], n_revisions):\n",
    "            img_file = dataset_path + img_id + '-' + str(max_t[img_id]-1) + '.png'\n",
    "            vs[t][i] = (cv2.imread(img_file, cv2.IMREAD_GRAYSCALE) / 255.).flatten()    \n",
    "    return vs, list(natsorted(max_t)), n_revisions\n",
    "\n",
    "\n",
    "def tabular_dataset_to_array(dataset_path):\n",
    "    # Get files with coords and save in an array vs\n",
    "    all_files = natsorted(glob.glob('{}*'.format(dataset_path)))\n",
    "    vs = [pd.read_csv(f, index_col=0).values for f in all_files] \n",
    "    # Get dataset info \n",
    "    df_temp = pd.read_csv(all_files[0], index_col=0)\n",
    "    n_timesteps = len(all_files)\n",
    "    return np.array(vs), list(df_temp.index), n_timesteps\n",
    "\n",
    "\n",
    "def dataset_as_array(dataset_path):\n",
    "    if dataset_id in IMAGE_DATASETS:\n",
    "         return image_dataset_to_array(dataset_path)\n",
    "    else:\n",
    "        return tabular_dataset_to_array(dataset_path)\n",
    "\n",
    "\n",
    "def get_nd_mov(dataset_id):\n",
    "    mov = []\n",
    "    dataset_path = './Datasets/' + dataset_id + '/'\n",
    "    # Get the nd data into arrays\n",
    "    vs, indexes, n_timesteps = dataset_as_array(dataset_path)\n",
    "    # Compute dists between 2 nd arrays\n",
    "    for t in range(n_timesteps - 1):\n",
    "        v_t = vs[t]\n",
    "        v_tp1 = vs[t+1]\n",
    "        mov_t = []\n",
    "        for a, b in zip(v_t, v_tp1):\n",
    "            mov_t.append(math.sqrt(np.sum(np.square(a - b))))\n",
    "        mov.append(np.array(mov_t)) \n",
    "    return np.array(mov).T, indexes, n_timesteps\n",
    "\n",
    "# dists, indexes, n_timesteps = get_nd_dists('quickdraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances\n",
    "mov_nd, indexes, n_timesteps = get_nd_mov(dataset_id)\n",
    "mov_md_dict = {}\n",
    "for p in projection_paths:\n",
    "    mov, _, _ = get_md_mov(p)\n",
    "    mov_md_dict[p] = mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_ids = ['stab_pearson', 'stab_spearman', 'stab_kendall', 'stab_kl', 'stab_stress_n', 'stab_stress_s',\n",
    "              'spat_pearson', 'spat_spearman', 'spat_kendall', 'spat_kl', 'spat_stress_n', 'spat_stress_s']\n",
    "\n",
    "for i in range(len(K_VALUES)):\n",
    "    metric_ids.append('spat_np_' + str(i+1))\n",
    "for i in range(len(K_VALUES)):\n",
    "    metric_ids.append('spat_nh_' + str(i+1))\n",
    "for i in range(len(K_VALUES)):\n",
    "    metric_ids.append('spat_trust_' + str(i+1))\n",
    "for i in range(len(K_VALUES)):\n",
    "    metric_ids.append('spat_cont_' + str(i+1))\n",
    "\n",
    "metric_results = pd.DataFrame(np.zeros((len(projection_paths), len(metric_ids))),\n",
    "                              index=projection_paths, columns=metric_ids)\n",
    "# metric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data\n",
    "mov_nd = mov_nd.flatten()\n",
    "for p in projection_paths:\n",
    "    mov_md = mov_md_dict[p].flatten()\n",
    "\n",
    "    # Correlation and divergence metrics\n",
    "    metric_results.loc[p]['stab_pearson']  = scipy.stats.pearsonr(mov_nd, mov_md)[0]\n",
    "    metric_results.loc[p]['stab_spearman'] = scipy.stats.spearmanr(mov_nd, mov_md)[0]\n",
    "    metric_results.loc[p]['stab_kendall']  = scipy.stats.kendalltau(mov_nd, mov_md)[0]\n",
    "    metric_results.loc[p]['stab_kl']       = scipy.stats.entropy(mov_nd, mov_md)\n",
    "\n",
    "    # Stress metrics\n",
    "    nd = mov_nd / max(mov_nd)\n",
    "    md = mov_md / max(mov_md)\n",
    "    metric_results.loc[p]['stab_stress_n'] = np.sum(np.square(nd - md)) / np.sum(np.square(nd))\n",
    "\n",
    "    nd = (mov_nd - np.mean(mov_nd)) / np.std(mov_nd)\n",
    "    md = (mov_md - np.mean(mov_md)) / np.std(mov_md)\n",
    "    metric_results.loc[p]['stab_stress_s'] = np.sum(np.square(nd - md)) / np.sum(np.square(nd))\n",
    "\n",
    "# display(metric_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trustworthiness_metric(nbrs_nd, nbrs_md, k):\n",
    "    sum_i = 0\n",
    "    for i in range(n_items):\n",
    "        # Look for false neighbors in a k sized neighborhood\n",
    "        knbrs_nd = nbrs_nd[i, 1:k+1]\n",
    "        knbrs_md = nbrs_md[i, 1:k+1]\n",
    "        U = np.setdiff1d(knbrs_nd, knbrs_md, assume_unique=True)\n",
    "\n",
    "        # For each false neighbor in mD, find out its rank in nD and sum it\n",
    "        sum_j = 0\n",
    "        for j in U: \n",
    "            sum_j += int(np.where(nbrs_md[i] == j)[0] - 1) - k   \n",
    "        sum_i += int(sum_j)\n",
    "\n",
    "    n = n_items\n",
    "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)))\n",
    "\n",
    "def continuity_metric(nbrs_nd, nbrs_md, k):\n",
    "    sum_i = 0\n",
    "    for i in range(n_items):\n",
    "        # Look for false neighbors in a k sized neighborhood\n",
    "        knbrs_nd = nbrs_nd[i, 1:k+1]\n",
    "        knbrs_md = nbrs_md[i, 1:k+1]\n",
    "        U = np.setdiff1d(knbrs_md, knbrs_nd, assume_unique=True)\n",
    "\n",
    "        # For each false neighbor in nD, find out its rank in mD and sum it\n",
    "        sum_j = 0\n",
    "        for j in U: \n",
    "            sum_j += int(np.where(nbrs_nd[i] == j)[0] - 1) - k   \n",
    "        sum_i += int(sum_j)\n",
    "\n",
    "    n = n_items\n",
    "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 273 ms, total: 22.4 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset_path = './Datasets/' + dataset_id + '/'\n",
    "vs_n, indexes, n_revisions = dataset_as_array(dataset_path)\n",
    "n_items = len(indexes)\n",
    "\n",
    "for p in projection_paths:\n",
    "    # Change axis in projection\n",
    "    vs_m, _, _ = get_projection_as_array(p)\n",
    "    vs_m = np.transpose(vs_m, (1,0,2))\n",
    "    \n",
    "    # Initialize structures\n",
    "    index_to_class = np.array([item.split('-')[0] for item in np.array(indexes)])\n",
    "    dists_nd_all = []\n",
    "    dists_md_all = [] \n",
    "    ngbr_preservation = np.zeros((n_timesteps, n_items, len(K_VALUES)))\n",
    "    ngbr_hit = np.zeros((n_timesteps, n_items, len(K_VALUES)))\n",
    "    trustworthiness = np.zeros((n_timesteps, len(K_VALUES)))\n",
    "    continuity = np.zeros((n_timesteps, len(K_VALUES)))\n",
    "    \n",
    "    for t in tqdm(range(n_timesteps)):\n",
    "        # Generate list of nearest neighbors for each item in timestep t\n",
    "        dists_nd, nbrs_nd = NearestNeighbors(n_neighbors=n_items, metric='euclidean',\n",
    "                                      algorithm='ball_tree').fit(vs_n[t]).kneighbors(vs_n[t])   \n",
    "        dists_md, nbrs_md = NearestNeighbors(n_neighbors=n_items, metric='euclidean',\n",
    "                                      algorithm='kd_tree').fit(vs_m[t]).kneighbors(vs_m[t])\n",
    "        \n",
    "        # Save distances to compute correlation/stress metrics\n",
    "        dists_nd_all.append(dists_nd)\n",
    "        dists_md_all.append(dists_md)\n",
    "        \n",
    "        # Check classes of neighbors for neighbor hit metric\n",
    "        for i in range(n_items):\n",
    "            i_class = index_to_class[i]\n",
    "            k_max = int(max(K_VALUES) * n_items)\n",
    "            ngbr_classes = index_to_class[nbrs_md[i, :k_max]]\n",
    "            for k_index, k_percentage in enumerate(K_VALUES):\n",
    "                k = max(int(k_percentage * n_items), 1)  # Avoid divisions by 0\n",
    "                ngbr_classes = ngbr_classes[:k]\n",
    "                nh = sum(map(lambda x: x == i_class, ngbr_classes)) / float(k)\n",
    "                ngbr_hit[t][i][k_index] = nh  \n",
    "\n",
    "        # Compute neighbor preservation for different values of k for each item \n",
    "        for i in range(n_items):\n",
    "            for k_index, k_percentage in enumerate(K_VALUES):\n",
    "                k = max(int(k_percentage * n_items), 1)  # Avoid divisions by 0\n",
    "                intersection = np.intersect1d(nbrs_nd[i, :k], nbrs_md[i, :k], assume_unique=True)\n",
    "                ngbr_preservation[t][i][k_index] = len(intersection) / float(k)\n",
    "                \n",
    "        # Compute trustworthiness\n",
    "        for k_index, k_percentage in enumerate(K_VALUES):\n",
    "            k = max(int(k_percentage * n_items), 1)  # Avoid divisions by 0\n",
    "            trustworthiness[t][k_index] = trustworthiness_metric(nbrs_nd, nbrs_md, k)\n",
    "            continuity[t][k_index] = continuity_metric(nbrs_nd, nbrs_md, k)\n",
    "        \n",
    "        \n",
    "    # Average values over TIME (axis 0)\n",
    "    ngbr_preservation = np.average(ngbr_preservation, axis=0)\n",
    "    ngbr_hit = np.average(ngbr_hit, axis=0)\n",
    "    trustworthiness = np.average(trustworthiness, axis=0)\n",
    "    continuity = np.average(continuity, axis=0)\n",
    "\n",
    "    # Then average values over all points (new axis 0)\n",
    "    ngbr_preservation = np.average(ngbr_preservation, axis=0)\n",
    "    ngbr_hit = np.average(ngbr_hit, axis=0)\n",
    "\n",
    "    # We get one value per k\n",
    "    for i in range(len(K_VALUES)):\n",
    "        metric_results.loc[p]['spat_np_' + str(i+1)]    = ngbr_preservation[i]\n",
    "        metric_results.loc[p]['spat_nh_' + str(i+1)]    = ngbr_hit[i]\n",
    "        metric_results.loc[p]['spat_trust_' + str(i+1)] = trustworthiness[i]\n",
    "        metric_results.loc[p]['spat_cont_' + str(i+1)]  = continuity[i]\n",
    "    \n",
    "    dists_nd_all = np.array(dists_nd_all)\n",
    "    dists_md_all = np.array(dists_md_all)\n",
    "    dists_nd_all = dists_nd_all.flatten()\n",
    "    dists_md_all = dists_md_all.flatten()\n",
    "\n",
    "    # Stress metrics\n",
    "    nd = dists_nd_all / max(dists_nd_all)\n",
    "    md = dists_md_all / max(dists_md_all)\n",
    "    metric_results.loc[p]['spat_stress_n'] = np.sum(np.square(nd - md)) / np.sum(np.square(nd))\n",
    "\n",
    "    nd = (dists_nd_all - np.mean(dists_nd_all)) / np.std(dists_nd_all)\n",
    "    md = (dists_md_all - np.mean(dists_md_all)) / np.std(dists_md_all)\n",
    "    metric_results.loc[p]['spat_stress_s'] = np.sum(np.square(nd - md)) / np.sum(np.square(nd))\n",
    "    \n",
    "    # Correlation and divergence metrics\n",
    "    metric_results.loc[p]['spat_pearson']  = scipy.stats.pearsonr(dists_nd_all, dists_md_all)[0]\n",
    "    metric_results.loc[p]['spat_spearman'] = scipy.stats.spearmanr(dists_nd_all, dists_md_all)[0]\n",
    "    metric_results.loc[p]['spat_kendall']  = scipy.stats.kendalltau(dists_nd_all, dists_md_all)[0]\n",
    "    metric_results.loc[p]['spat_kl']       = scipy.stats.entropy(dists_nd_all, dists_md_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(trustworthiness)\n",
    "# plt.plot(continuity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Output/sorts-tsne_s1_30p.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>./Output/sorts-tsne_s1_30p.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stab_pearson</th>\n",
       "      <td>0.034644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab_spearman</th>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab_kendall</th>\n",
       "      <td>0.057688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab_kl</th>\n",
       "      <td>0.815166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab_stress_n</th>\n",
       "      <td>0.898755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab_stress_s</th>\n",
       "      <td>1.930713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_pearson</th>\n",
       "      <td>0.022570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_spearman</th>\n",
       "      <td>0.005598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_kendall</th>\n",
       "      <td>0.010653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_kl</th>\n",
       "      <td>1.060794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_stress_n</th>\n",
       "      <td>0.961652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_stress_s</th>\n",
       "      <td>1.954859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_1</th>\n",
       "      <td>0.991582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_2</th>\n",
       "      <td>0.991582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_3</th>\n",
       "      <td>0.708099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_4</th>\n",
       "      <td>0.628954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_5</th>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_6</th>\n",
       "      <td>0.595057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_7</th>\n",
       "      <td>0.573087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_8</th>\n",
       "      <td>0.566454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_9</th>\n",
       "      <td>0.567201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_10</th>\n",
       "      <td>0.574936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_11</th>\n",
       "      <td>0.574936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_12</th>\n",
       "      <td>0.587599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_13</th>\n",
       "      <td>0.599324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_14</th>\n",
       "      <td>0.593982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_15</th>\n",
       "      <td>0.591241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_16</th>\n",
       "      <td>0.591241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_17</th>\n",
       "      <td>0.588432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_18</th>\n",
       "      <td>0.587464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_19</th>\n",
       "      <td>0.588597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_np_20</th>\n",
       "      <td>0.591518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_1</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_2</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_3</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_4</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_5</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_6</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_7</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_8</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_9</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_10</th>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_11</th>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_12</th>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_13</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_14</th>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_15</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_16</th>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_17</th>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_18</th>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_19</th>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_nh_20</th>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_1</th>\n",
       "      <td>0.923620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_2</th>\n",
       "      <td>0.923620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_3</th>\n",
       "      <td>0.912054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_4</th>\n",
       "      <td>0.905051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_5</th>\n",
       "      <td>0.899206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_6</th>\n",
       "      <td>0.899206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_7</th>\n",
       "      <td>0.895554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_8</th>\n",
       "      <td>0.892875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_9</th>\n",
       "      <td>0.890706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_10</th>\n",
       "      <td>0.889418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_11</th>\n",
       "      <td>0.889418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_12</th>\n",
       "      <td>0.888168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_13</th>\n",
       "      <td>0.883158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_14</th>\n",
       "      <td>0.879615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_15</th>\n",
       "      <td>0.876532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_16</th>\n",
       "      <td>0.876532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_17</th>\n",
       "      <td>0.873878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_18</th>\n",
       "      <td>0.872256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_19</th>\n",
       "      <td>0.871153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_trust_20</th>\n",
       "      <td>0.870228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_1</th>\n",
       "      <td>0.947971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_2</th>\n",
       "      <td>0.947971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_3</th>\n",
       "      <td>0.927933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_4</th>\n",
       "      <td>0.910362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_5</th>\n",
       "      <td>0.891226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_6</th>\n",
       "      <td>0.891226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_7</th>\n",
       "      <td>0.877370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_8</th>\n",
       "      <td>0.870190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_9</th>\n",
       "      <td>0.866909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_10</th>\n",
       "      <td>0.864307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_11</th>\n",
       "      <td>0.864307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_12</th>\n",
       "      <td>0.861179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_13</th>\n",
       "      <td>0.855405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_14</th>\n",
       "      <td>0.850155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_15</th>\n",
       "      <td>0.845391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_16</th>\n",
       "      <td>0.845391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_17</th>\n",
       "      <td>0.841363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_18</th>\n",
       "      <td>0.838506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_19</th>\n",
       "      <td>0.835886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spat_cont_20</th>\n",
       "      <td>0.834084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ./Output/sorts-tsne_s1_30p.csv\n",
       "stab_pearson                         0.034644\n",
       "stab_spearman                        0.085714\n",
       "stab_kendall                         0.057688\n",
       "stab_kl                              0.815166\n",
       "stab_stress_n                        0.898755\n",
       "stab_stress_s                        1.930713\n",
       "spat_pearson                         0.022570\n",
       "spat_spearman                        0.005598\n",
       "spat_kendall                         0.010653\n",
       "spat_kl                              1.060794\n",
       "spat_stress_n                        0.961652\n",
       "spat_stress_s                        1.954859\n",
       "spat_np_1                            0.991582\n",
       "spat_np_2                            0.991582\n",
       "spat_np_3                            0.708099\n",
       "spat_np_4                            0.628954\n",
       "spat_np_5                            0.595057\n",
       "spat_np_6                            0.595057\n",
       "spat_np_7                            0.573087\n",
       "spat_np_8                            0.566454\n",
       "spat_np_9                            0.567201\n",
       "spat_np_10                           0.574936\n",
       "spat_np_11                           0.574936\n",
       "spat_np_12                           0.587599\n",
       "spat_np_13                           0.599324\n",
       "spat_np_14                           0.593982\n",
       "spat_np_15                           0.591241\n",
       "spat_np_16                           0.591241\n",
       "spat_np_17                           0.588432\n",
       "spat_np_18                           0.587464\n",
       "spat_np_19                           0.588597\n",
       "spat_np_20                           0.591518\n",
       "spat_nh_1                            1.000000\n",
       "spat_nh_2                            1.000000\n",
       "spat_nh_3                            0.500000\n",
       "spat_nh_4                            0.333333\n",
       "spat_nh_5                            0.250000\n",
       "spat_nh_6                            0.250000\n",
       "spat_nh_7                            0.200000\n",
       "spat_nh_8                            0.166667\n",
       "spat_nh_9                            0.142857\n",
       "spat_nh_10                           0.125000\n",
       "spat_nh_11                           0.125000\n",
       "spat_nh_12                           0.111111\n",
       "spat_nh_13                           0.100000\n",
       "spat_nh_14                           0.090909\n",
       "spat_nh_15                           0.083333\n",
       "spat_nh_16                           0.083333\n",
       "spat_nh_17                           0.076923\n",
       "spat_nh_18                           0.071429\n",
       "spat_nh_19                           0.066667\n",
       "spat_nh_20                           0.062500\n",
       "spat_trust_1                         0.923620\n",
       "spat_trust_2                         0.923620\n",
       "spat_trust_3                         0.912054\n",
       "spat_trust_4                         0.905051\n",
       "spat_trust_5                         0.899206\n",
       "spat_trust_6                         0.899206\n",
       "spat_trust_7                         0.895554\n",
       "spat_trust_8                         0.892875\n",
       "spat_trust_9                         0.890706\n",
       "spat_trust_10                        0.889418\n",
       "spat_trust_11                        0.889418\n",
       "spat_trust_12                        0.888168\n",
       "spat_trust_13                        0.883158\n",
       "spat_trust_14                        0.879615\n",
       "spat_trust_15                        0.876532\n",
       "spat_trust_16                        0.876532\n",
       "spat_trust_17                        0.873878\n",
       "spat_trust_18                        0.872256\n",
       "spat_trust_19                        0.871153\n",
       "spat_trust_20                        0.870228\n",
       "spat_cont_1                          0.947971\n",
       "spat_cont_2                          0.947971\n",
       "spat_cont_3                          0.927933\n",
       "spat_cont_4                          0.910362\n",
       "spat_cont_5                          0.891226\n",
       "spat_cont_6                          0.891226\n",
       "spat_cont_7                          0.877370\n",
       "spat_cont_8                          0.870190\n",
       "spat_cont_9                          0.866909\n",
       "spat_cont_10                         0.864307\n",
       "spat_cont_11                         0.864307\n",
       "spat_cont_12                         0.861179\n",
       "spat_cont_13                         0.855405\n",
       "spat_cont_14                         0.850155\n",
       "spat_cont_15                         0.845391\n",
       "spat_cont_16                         0.845391\n",
       "spat_cont_17                         0.841363\n",
       "spat_cont_18                         0.838506\n",
       "spat_cont_19                         0.835886\n",
       "spat_cont_20                         0.834084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "display(metric_results.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results.to_csv('./Metrics/results/{}.csv'.format(dataset_id))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
