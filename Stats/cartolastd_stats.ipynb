{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ipsilva/Repositories/dynamic-projections/Datasets/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "curr_folder = os.getcwd() + \"/\"\n",
    "datasets_folder = curr_folder[:-6] + \"Datasets/\"\n",
    "datasets_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ipsilva/Repositories/dynamic-projections/Datasets/gaussians',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/quickdraw',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/sorts',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/walk',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/nnset',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/fashion',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/cifar10cnn',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/esc50',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/qtables',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/cartolastd']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_subfolders = []\n",
    "for i in os.walk(datasets_folder):\n",
    "    datasets_subfolders.append(i[0])\n",
    "\n",
    "datasets_subfolders = datasets_subfolders[1:]\n",
    "datasets_subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ipsilva/Repositories/dynamic-projections/Datasets/cartolastd'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_number = 9\n",
    "selected_dataset = datasets_subfolders[dataset_number]\n",
    "selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cartolastd-16.csv',\n",
       " 'cartolastd-12.csv',\n",
       " 'cartolastd-0.csv',\n",
       " 'cartolastd-7.csv',\n",
       " 'cartolastd-13.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "files = [f for f in listdir(selected_dataset) if isfile(join(selected_dataset, f))]\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13224, 17)     0    1    2    3         4    5    6         7    8    9    10   11   12  \\\n",
      "0  0.0  0.0  0.0  0.0  0.058824  0.0  0.0  0.021116  0.0  0.0  0.0  0.0  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.022222  0.0  0.0  0.023932  0.0  0.0  0.0  0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "    13   14   15   16  \n",
      "0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "obs_per_timestep = []\n",
    "for file in files:\n",
    "    file_loc = selected_dataset + \"/\" + file\n",
    "    ndf = pd.read_csv(file_loc)\n",
    "    df = df.append(ndf)\n",
    "    obs_per_timestep.append(ndf.shape[0])\n",
    "    \n",
    "median_obs_per_timestep = np.median(obs_per_timestep)\n",
    "dev_obs_per_timestep = np.std(obs_per_timestep)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(min_max_scaler.fit_transform(df.drop(columns=df.columns[0], axis=1)))\n",
    "print(df.shape, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def intrisic_dim(dataframe, target_variance):\n",
    "    pca = PCA()\n",
    "\n",
    "    principalComponents = pca.fit_transform(df)\n",
    "\n",
    "    list_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    final_var = 0\n",
    "    dims = 0\n",
    "    for var in list_variance:\n",
    "        final_var += var\n",
    "        dims += 1\n",
    "        if final_var > target_variance:\n",
    "            break\n",
    "    return dims, final_var, principalComponents[:dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time-steps: 19\n",
      "Registers per time-step (median): 696.0\n",
      "Registers per time-step (deviation): 0.0\n",
      "Total dimensions: 17\n",
      "Intrinsic dimensions: 7\n",
      "Total variance: 0.9104838185254228\n"
     ]
    }
   ],
   "source": [
    "target_variance = 0.9\n",
    "\n",
    "(dims, final_var, components) = intrisic_dim(df, target_variance)\n",
    "\n",
    "print(\"Total time-steps:\", len(obs_per_timestep))\n",
    "print(\"Registers per time-step (median):\", median_obs_per_timestep)\n",
    "print(\"Registers per time-step (deviation):\", dev_obs_per_timestep)\n",
    "print(\"Total dimensions:\", df.shape[1])\n",
    "print(\"Intrinsic dimensions:\", dims)\n",
    "print(\"Total variance:\", final_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
