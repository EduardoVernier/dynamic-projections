{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ipsilva/Repositories/dynamic-projections/Datasets/'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "curr_folder = os.getcwd() + \"/\"\n",
    "datasets_folder = curr_folder[:-6] + \"Datasets/\"\n",
    "datasets_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ipsilva/Repositories/dynamic-projections/Datasets/gaussians',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/quickdraw',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/sorts',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/walk',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/nnset',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/fashion',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/cifar10cnn',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/esc50',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/qtables',\n",
       " '/home/ipsilva/Repositories/dynamic-projections/Datasets/cartolastd']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_subfolders = []\n",
    "for i in os.walk(datasets_folder):\n",
    "    datasets_subfolders.append(i[0])\n",
    "\n",
    "datasets_subfolders = datasets_subfolders[1:]\n",
    "datasets_subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ipsilva/Repositories/dynamic-projections/Datasets/fashion'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_number = 5\n",
    "selected_dataset = datasets_subfolders[dataset_number]\n",
    "selected_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tshirt-787-0.png',\n",
       " 'bag-258-1.png',\n",
       " 'trouser-450-8.png',\n",
       " 'trouser-426-3.png',\n",
       " 'sandal-416-2.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "files = [f for f in listdir(selected_dataset) if isfile(join(selected_dataset, f))]\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)      (0, 0)    (0, 1)    (0, 2)   (0, 3)    (0, 4)    (0, 5)    (0, 6)  \\\n",
      "0  0.008197  0.000000  0.200000  0.00000  0.280851  0.000000  0.000000   \n",
      "1  0.058824  0.000000  0.000000  0.00000  0.160784  0.250980  0.501961   \n",
      "2  0.739130  0.827586  0.333333  0.00000  0.000000  0.250000  0.448276   \n",
      "3  0.000000  0.474820  0.033557  0.00000  0.117347  0.052632  0.410480   \n",
      "4  0.033113  0.047059  0.247863  0.11828  0.241379  0.086275  0.000000   \n",
      "\n",
      "     (0, 7)  (0, 8)    (0, 9)  ...  (27, 18)  (27, 19)  (27, 20)  (27, 21)  \\\n",
      "0  0.428571     0.0  0.313725  ...  0.066667  0.000000       0.0  0.788235   \n",
      "1  0.000000     0.0  0.200000  ...  0.000000  0.000000       0.0  0.000000   \n",
      "2  0.000000     0.0  0.000000  ...  0.000000  0.000000       0.0  0.000000   \n",
      "3  0.314286     0.0  1.000000  ...  0.164706  0.000000       0.0  0.187879   \n",
      "4  0.403922     0.0  0.270588  ...  0.874510  0.019608       0.0  0.176471   \n",
      "\n",
      "   (27, 22)  (27, 23)  (27, 24)  (27, 25)  (27, 26)  (27, 27)  \n",
      "0  0.454902  0.129412  0.054902  0.023364  0.000000  0.000000  \n",
      "1  0.396078  0.266667  0.000000  0.000000  0.286275  0.000000  \n",
      "2  0.189189  0.000000  0.148148  0.000000  0.000000  0.000000  \n",
      "3  0.864865  0.000000  0.000000  0.000000  0.171429  0.016949  \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "images_as_lines = []\n",
    "\n",
    "obs_per_timestep = {}\n",
    "for file in files:\n",
    "    file_loc = selected_dataset + \"/\" + file\n",
    "    image = cv2.imread(file_loc)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    line = normalize(gray, axis=0, norm='max').reshape(-1)\n",
    "    images_as_lines.append(line)\n",
    "    \n",
    "    time = re.search(\"[0-9]+.png$\", file).group()\n",
    "    try:\n",
    "        obs_per_timestep[time] == False\n",
    "        obs_per_timestep[time] += 1\n",
    "    except:\n",
    "        obs_per_timestep[time] = 1\n",
    "\n",
    "obs_per_timestep = list(obs_per_timestep.values())\n",
    "median_obs_per_timestep = np.median(obs_per_timestep)\n",
    "dev_obs_per_timestep = np.std(obs_per_timestep)\n",
    "\n",
    "(i,j) = gray.shape\n",
    "i_l = [i_e for i_e in range(i)]\n",
    "j_l = [j_e for j_e in range(j)]\n",
    "columns = list(product(i_l, j_l))        \n",
    "df = pd.DataFrame(images_as_lines, columns=columns)\n",
    "print(df.shape, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def intrisic_dim(dataframe, target_variance):\n",
    "    pca = PCA()\n",
    "\n",
    "    principalComponents = pca.fit_transform(df)\n",
    "\n",
    "    list_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    final_var = 0\n",
    "    dims = 0\n",
    "    for var in list_variance:\n",
    "        final_var += var\n",
    "        dims += 1\n",
    "        if final_var > target_variance:\n",
    "            break\n",
    "    return dims, final_var, principalComponents[:dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time-steps: 10\n",
      "Registers per time-step (median): 1000.0\n",
      "Registers per time-step (deviation): 0.0\n",
      "Total dimensions: 784\n",
      "Intrinsic dimensions: 541\n",
      "Total variance: 0.9000049253393786\n"
     ]
    }
   ],
   "source": [
    "target_variance = 0.9\n",
    "\n",
    "(dims, final_var, components) = intrisic_dim(df, target_variance)\n",
    "\n",
    "print(\"Total time-steps:\", len(obs_per_timestep))\n",
    "print(\"Registers per time-step (median):\", median_obs_per_timestep)\n",
    "print(\"Registers per time-step (deviation):\", dev_obs_per_timestep)\n",
    "print(\"Total dimensions:\", df.shape[1])\n",
    "print(\"Intrinsic dimensions:\", dims)\n",
    "print(\"Total variance:\", final_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
